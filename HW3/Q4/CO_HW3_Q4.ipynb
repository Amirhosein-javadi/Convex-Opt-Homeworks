{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: iris_flower_data.jl\n",
    "Authors: Reese Pathak, Stephen Boyd\n",
    "====================================\n",
    "Iris dataset, taken from \n",
    "http://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "features = [\"sepal length (cm)\";  \n",
    "            \"sepal width (cm)\";\n",
    "            \"petal length (cm)\";\n",
    "            \"petal width (cm)\"] \n",
    "\n",
    "labels = [\"setosa\"; \"versicolor\"; \"virginica\"]\n",
    "\n",
    "X = [4.9 4.8 6.0 6.4 5.1 6.7 4.3 6.8 6.3 6.7 4.9 4.4 4.6 7.9 5.8 7.0 7.7 5.6 5.7 5.9 5.0 5.7 6.4 5.8 5.1 6.7 6.0 6.4 6.3 4.8 5.5 4.7 5.5 5.0 6.3 6.4 6.3 4.9 6.5 5.7 6.6 6.0 6.0 5.5 6.7 5.6 6.7 6.1 5.1 7.7 7.2 5.5 5.2 6.5 5.8 7.2 5.4 6.3 7.6 6.4 6.7 6.5 5.6 5.7 4.7 5.0 5.4 5.0 6.3 5.5 6.1 6.2 6.1 5.3 6.3 6.2 5.6 5.0 5.8 5.8 6.2 5.4 6.5 5.9 4.9 4.6 7.2 6.9 6.4 5.5 6.0 6.3 4.9 4.8 6.7 5.1 7.3 5.1 6.9 4.9 6.1 7.7 6.1 5.9 4.6 5.2 6.9 5.8 6.3 6.1 5.4 4.8 7.7 6.7 4.5 5.4 5.0 5.1 5.6 4.6 5.7 5.0 5.7 6.8 6.4 5.0 5.7 5.6 5.0 4.8 5.2 7.1 6.5 4.4 6.2 6.8 7.4 5.1 5.1 5.5 4.4 6.0 6.6 5.1 5.8 5.4 6.9 5.0 5.7 5.2; \n",
    "    3.1 3.4 2.7 3.2 3.8 3.1 3.0 3.2 2.8 3.1 3.6 3.2 3.6 3.8 2.6 3.2 2.6 3.0 2.8 3.2 3.2 3.8 2.8 2.7 3.7 3.0 3.0 2.8 2.5 3.0 2.6 3.2 4.2 3.5 2.9 2.9 2.5 2.5 2.8 2.6 2.9 2.2 2.2 2.3 2.5 2.7 3.0 2.6 2.5 2.8 3.6 2.5 2.7 3.0 2.7 3.0 3.4 2.7 3.0 3.1 3.3 3.2 2.9 2.5 3.2 3.3 3.0 3.0 3.4 3.5 2.9 2.8 3.0 3.7 3.3 2.2 2.5 3.4 2.7 4.0 2.9 3.7 3.0 3.0 3.0 3.2 3.2 3.1 3.2 2.4 2.9 2.3 3.1 3.0 3.1 3.8 2.9 3.4 3.1 2.4 2.8 3.0 3.0 3.0 3.4 3.5 3.2 2.8 3.3 2.8 3.9 3.1 3.8 3.3 2.3 3.9 3.6 3.5 3.0 3.1 2.9 3.4 4.4 2.8 2.7 2.0 2.8 2.8 2.3 3.4 4.1 3.0 3.0 3.0 3.4 3.0 2.8 3.3 3.5 2.4 2.9 3.4 3.0 3.8 2.7 3.4 3.1 3.5 3.0 3.4; \n",
    "    1.5 1.6 5.1 4.5 1.9 4.7 1.1 5.9 5.1 5.6 1.4 1.3 1.0 6.4 4.0 4.7 6.9 4.5 4.1 4.8 1.2 1.7 5.6 4.1 1.5 5.2 4.8 5.6 5.0 1.4 4.4 1.3 1.4 1.3 5.6 4.3 4.9 4.5 4.6 3.5 4.6 4.0 5.0 4.0 5.8 4.2 5.0 5.6 3.0 6.7 6.1 4.0 3.9 5.2 5.1 5.8 1.5 4.9 6.6 5.5 5.7 5.1 3.6 5.0 1.6 1.4 4.5 1.6 5.6 1.3 4.7 4.8 4.9 1.5 4.7 4.5 3.9 1.5 3.9 1.2 4.3 1.5 5.8 5.1 1.4 1.4 6.0 5.4 5.3 3.8 4.5 4.4 1.5 1.4 4.4 1.6 6.3 1.5 5.1 3.3 4.7 6.1 4.6 4.2 1.4 1.5 5.7 5.1 6.0 4.0 1.3 1.6 6.7 5.7 1.3 1.7 1.4 1.4 4.1 1.5 4.2 1.6 1.5 4.8 5.3 3.5 4.5 4.9 3.3 1.9 1.5 5.9 5.5 1.3 5.4 5.5 6.1 1.7 1.4 3.7 1.4 4.5 4.4 1.5 5.1 1.7 4.9 1.6 4.2 1.4; \n",
    "    0.1 0.2 1.6 1.5 0.4 1.5 0.1 2.3 1.5 2.4 0.1 0.2 0.2 2.0 1.2 1.4 2.3 1.5 1.3 1.8 0.2 0.3 2.1 1.0 0.4 2.3 1.8 2.2 1.9 0.3 1.2 0.2 0.2 0.3 1.8 1.3 1.5 1.7 1.5 1.0 1.3 1.0 1.5 1.3 1.8 1.3 1.7 1.4 1.1 2.0 2.5 1.3 1.4 2.0 1.9 1.6 0.4 1.8 2.1 1.8 2.5 2.0 1.3 2.0 0.2 0.2 1.5 0.2 2.4 0.2 1.4 1.8 1.8 0.2 1.6 1.5 1.1 0.2 1.2 0.2 1.3 0.2 2.2 1.8 0.2 0.2 1.8 2.1 2.3 1.1 1.5 1.3 0.2 0.1 1.4 0.2 1.8 0.2 2.3 1.0 1.2 2.3 1.4 1.5 0.3 0.2 2.3 2.4 2.5 1.3 0.4 0.2 2.2 2.1 0.3 0.4 0.2 0.3 1.3 0.2 1.3 0.4 0.4 1.4 1.9 1.0 1.3 2.0 1.0 0.2 0.1 2.1 1.8 0.2 2.3 2.1 1.9 0.5 0.2 1.0 0.2 1.6 1.4 0.3 1.9 0.2 1.5 0.6 1.2 0.2];\n",
    "\n",
    "y  =[1.0,1.0,2.0,2.0,1.0,2.0,1.0,3.0,3.0,3.0,1.0,1.0,1.0,3.0,2.0,2.0,3.0,2.0,2.0,2.0,1.0,1.0,3.0,2.0,1.0,3.0,3.0,3.0,3.0,1.0,2.0,1.0,1.0,1.0,3.0,2.0,2.0,3.0,2.0,2.0,2.0,2.0,3.0,2.0,3.0,2.0,2.0,3.0,2.0,3.0,3.0,2.0,2.0,3.0,3.0,3.0,1.0,3.0,3.0,3.0,3.0,3.0,2.0,3.0,1.0,1.0,2.0,1.0,3.0,1.0,2.0,3.0,3.0,1.0,2.0,2.0,2.0,1.0,2.0,1.0,2.0,1.0,3.0,3.0,1.0,1.0,3.0,3.0,3.0,2.0,2.0,2.0,1.0,1.0,2.0,1.0,3.0,1.0,3.0,2.0,2.0,3.0,2.0,2.0,1.0,1.0,3.0,3.0,3.0,2.0,1.0,1.0,3.0,3.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,2.0,3.0,2.0,2.0,3.0,2.0,1.0,1.0,3.0,3.0,1.0,3.0,3.0,3.0,1.0,1.0,2.0,1.0,2.0,2.0,1.0,3.0,1.0,2.0,1.0,2.0,1.0]\n",
    "\n",
    "\n",
    "# function to get and format dataset \n",
    "if false\n",
    "    function get_iris_data()\n",
    "        srand(5)\n",
    "        # Formatting dataset (must Pkg.add(\"RDatasets\"))\n",
    "        iris = dataset(\"datasets\", \"iris\")\n",
    "        data = convert(Array, iris)\n",
    "        X = transpose(1.0*data[:, 1:4]);\n",
    "        perm = randperm(150);\n",
    "        X = X[:, perm]; \n",
    "        y = [ones(50); 2*ones(50); 3*ones(50)];\n",
    "        y = y[perm];\n",
    "        return (X, y)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confusion_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "File: iris_multiclass_helpers.jl\n",
    "Authors: Reese Pathak, Stephen Boyd\n",
    "------------------------------------\n",
    "Helper methods for the iris dataset\n",
    "multiclass classification problem.\n",
    "\"\"\"\n",
    "\n",
    "function argmax_by_row(A) \n",
    "    \"\"\"\n",
    "    Function: argmax_by_row(A)\n",
    "    Usage: class_labels = argmax_by_row(Y_tilde)\n",
    "    ---------------------------------------------\n",
    "    Returns a vector with each entry equal to \n",
    "    the index of maximum element (argmax) for the \n",
    "    corresponding row vector in the input matrix \n",
    "    A. Data type is Float64. \n",
    "    \"\"\"\n",
    "    return 1.0 * ind2sub(A, vec(findmax(A, dims =2)[2]))[2]\n",
    "end\n",
    "\n",
    "\n",
    "function confusion_matrix(y_hat, y_true)\n",
    "    \"\"\"\n",
    "    Function: confusion_matrix(y_hat, y_true)\n",
    "    Usage: conf_matrix = confusion_matrix(y_hat, y_test)\n",
    "    ----------------------------------------------------\n",
    "    Returns a 3x3 matrix where the C[i,j] is the number \n",
    "    of predictions for which y_hat[k] == i and \n",
    "    y_hat[k] == j. Data type is Float64\n",
    "    \"\"\"\n",
    "    C = zeros(3,3)\n",
    "    for i in 1:3\n",
    "        for j in 1:3\n",
    "            C[i,j] = 1.0 * sum((y_hat .== i) .* (y_true .== j))\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = X[:,1:100];\n",
    "Test_X  = X[:,101:150];\n",
    "Train_y = y[1:100];\n",
    "Test_y  = y[101:150];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Model_1_y = 2 * (Train_y .== 1) .- 1;\n",
    "Model_1 = Train_X' \\ Train_Model_1_y;\n",
    "Train_Model_2_y = 2 * (Train_y .== 2) .- 1;\n",
    "Model_2 = Train_X' \\ Train_Model_2_y;\n",
    "Train_Model_3_y = 2 * (Train_y .== 3) .- 1;\n",
    "Model_3 = Train_X' \\ Train_Model_3_y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Error Rate on Train Data is 0.0\n",
      "Model 1 Error Rate on Test Datais 0.0\n"
     ]
    }
   ],
   "source": [
    "Test_Model_1_y = 2 * (Test_y .== 1) .- 1;\n",
    "Model_1_Train_y_hat = sign.(Train_X' * Model_1);\n",
    "Model_1_Train_Error_Rate = 1 - sum(Model_1_Train_y_hat .== Train_Model_1_y) / 100;\n",
    "Model_1_Test_y_hat = sign.(Test_X' * Model_1);\n",
    "Model_1_Test_Error_Rate = 1 - sum(Model_1_Test_y_hat .== Test_Model_1_y) / 50;\n",
    "println(\"Model 1 Error Rate on Train Data is \" * string(round(Model_1_Train_Error_Rate; digits = 5)))\n",
    "println(\"Model 1 Error Rate on Test Datais \" * string(round(Model_1_Test_Error_Rate; digits = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Error Rate on Train Data is 0.3\n",
      "Model 2 Error Rate on Test Datais is 0.24\n"
     ]
    }
   ],
   "source": [
    "Test_Model_2_y = 2 * (Test_y .== 2) .- 1;\n",
    "Model_2_Train_y_hat = sign.(Train_X' * Model_2);\n",
    "Model_2_Train_Error_Rate = 1 - sum(Model_2_Train_y_hat .== Train_Model_2_y) / 100;\n",
    "Model_2_Test_y_hat = sign.(Test_X' * Model_2);\n",
    "Model_2_Test_Error_Rate = 1 - sum(Model_2_Test_y_hat .== Test_Model_2_y) / 50;\n",
    "println(\"Model 2 Error Rate on Train Data is \" * string(round(Model_2_Train_Error_Rate; digits = 5)))\n",
    "println(\"Model 2 Error Rate on Test Datais is \" * string(round(Model_2_Test_Error_Rate; digits = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Error Rate on Train Data is 0.1\n",
      "Model 3 Error Rate on Test Datais 0.34\n"
     ]
    }
   ],
   "source": [
    "Test_Model_3_y = 2 * (Test_y .== 3) .- 1;\n",
    "Model_3_Train_y_hat = sign.(Train_X' * Model_3);\n",
    "Model_3_Train_Error_Rate = 1 - sum(Model_3_Train_y_hat .== Train_Model_3_y) / 100;\n",
    "Model_3_Test_y_hat = sign.(Test_X' * Model_2);\n",
    "Model_3_Test_Error_Rate = 1 - sum(Model_3_Test_y_hat .== Test_Model_3_y) / 50;\n",
    "println(\"Model 3 Error Rate on Train Data is \" * string(round(Model_3_Train_Error_Rate; digits = 5)))\n",
    "println(\"Model 3 Error Rate on Test Datais \" * string(round(Model_3_Test_Error_Rate; digits = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix :\n",
      "[29.0, 0.0, 0.0]\n",
      "[0.0, 22.0, 8.0]\n",
      "[0.0, 13.0, 28.0]\n",
      "\n",
      "Test Confusion Matrix :\n",
      "[21.0, 0.0, 0.0]\n",
      "[0.0, 8.0, 1.0]\n",
      "[0.0, 7.0, 13.0]\n"
     ]
    }
   ],
   "source": [
    "Model = [Model_1 Model_2 Model_3];\n",
    "Train_y_hat = reshape(getindex.(findmax(Train_X' * Model, dims =2)[2], 2),(100,));\n",
    "Train_Confusion_Matrix = confusion_matrix(Train_y_hat, Train_y);\n",
    "println(\"Train Confusion Matrix :\")\n",
    "println(Train_Confusion_Matrix[1,:])\n",
    "println(Train_Confusion_Matrix[2,:])\n",
    "println(Train_Confusion_Matrix[3,:])\n",
    "\n",
    "println()\n",
    "\n",
    "Test_y_hat = reshape(getindex.(findmax(Test_X' * Model, dims =2)[2], 2),(50,));\n",
    "Test_Confusion_Matrix = confusion_matrix(Test_y_hat, Test_y)\n",
    "println(\"Test Confusion Matrix :\")\n",
    "println(Test_Confusion_Matrix[1,:])\n",
    "println(Test_Confusion_Matrix[2,:])\n",
    "println(Test_Confusion_Matrix[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Error Rate on Train Data is 0.21\n"
     ]
    }
   ],
   "source": [
    "Model_Train_Error_Rate = 1 - sum([Train_Confusion_Matrix[1,1],Train_Confusion_Matrix[2,2],Train_Confusion_Matrix[3,3]]) / 100;\n",
    "println(\"Model Error Rate on Train Data is \" * string(round(Model_Train_Error_Rate; digits = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Error Rate on Test Data is 0.16\n"
     ]
    }
   ],
   "source": [
    "Model_Test_Error_Rate = 1 - sum([Test_Confusion_Matrix[1,1],Test_Confusion_Matrix[2,2],Test_Confusion_Matrix[3,3]]) / 50;\n",
    "println(\"Model Error Rate on Test Data is \" * string(round(Model_Test_Error_Rate; digits = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
